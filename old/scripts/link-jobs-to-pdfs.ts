import { createClient } from '@supabase/supabase-js'
import dotenv from 'dotenv'
import path from 'path'
import { fileURLToPath } from 'url'

const __filename = fileURLToPath(import.meta.url)
const __dirname = path.dirname(__filename)

dotenv.config({ path: path.join(__dirname, '..', '.env.local') })

const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL!
const supabaseServiceKey = process.env.SUPABASE_SERVICE_ROLE_KEY!

const supabase = createClient(supabaseUrl, supabaseServiceKey)

async function getAllJobs() {
  const allJobs: any[] = []
  let offset = 0
  const limit = 1000

  console.log('ğŸ“¥ æ±‚äººãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...')

  while (true) {
    const { data: jobs, error } = await supabase
      .from('jobs')
      .select('id, title, company_name')
      .range(offset, offset + limit - 1)

    if (error) {
      console.error('âŒ å–å¾—ã‚¨ãƒ©ãƒ¼:', error)
      break
    }

    if (!jobs || jobs.length === 0) {
      break
    }

    allJobs.push(...jobs)
    console.log(`  ğŸ“¦ ${allJobs.length}ä»¶å–å¾—æ¸ˆã¿...`)

    if (jobs.length < limit) {
      break
    }

    offset += limit
  }

  return allJobs
}

async function linkJobsToPdfs() {
  console.log('ğŸ”— æ±‚äººã¨PDFãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ç´ä»˜ã‘ã¾ã™...\n')

  // ã™ã¹ã¦ã®æ±‚äººã‚’å–å¾—ï¼ˆãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å¯¾å¿œï¼‰
  const jobs = await getAllJobs()

  if (jobs.length === 0) {
    console.error('âŒ æ±‚äººãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ')
    return
  }

  console.log(`\nğŸ“Š ${jobs.length}ä»¶ã®æ±‚äººã‚’å–å¾—ã—ã¾ã—ãŸ`)
  console.log('ğŸ”„ ç´ä»˜ã‘ã‚’é–‹å§‹ã—ã¾ã™...\n')

  let successCount = 0
  let notFoundCount = 0
  let errorCount = 0

  for (let i = 0; i < jobs.length; i++) {
    const job = jobs[i]

    // é€²æ—è¡¨ç¤ºï¼ˆ100ä»¶ã”ã¨ï¼‰
    if ((i + 1) % 100 === 0) {
      console.log(`ğŸ“Š é€²æ—: ${i + 1}/${jobs.length} (æˆåŠŸ: ${successCount}, æœªç™ºè¦‹: ${notFoundCount})`)
    }

    try {
      // company_nameã¨job_titleã§éƒ¨åˆ†ä¸€è‡´æ¤œç´¢
      const { data: mappings, error: mappingError } = await supabase
        .from('pdf_mappings')
        .select('id, job_title')
        .eq('company_name', job.company_name)
        .ilike('job_title', `%${job.title}%`)
        .limit(1)

      if (mappingError) {
        console.error(`âŒ ã‚¨ãƒ©ãƒ¼ [${job.company_name}]: ${mappingError.message}`)
        errorCount++
        continue
      }

      if (mappings && mappings.length > 0) {
        // job_idã‚’æ›´æ–°
        const { error: updateError } = await supabase
          .from('pdf_mappings')
          .update({ job_id: job.id })
          .eq('id', mappings[0].id)

        if (updateError) {
          console.error(`âŒ æ›´æ–°å¤±æ•— [${job.title}]: ${updateError.message}`)
          errorCount++
        } else {
          successCount++
        }
      } else {
        notFoundCount++
      }
    } catch (error) {
      console.error(`âŒ ä¾‹å¤–ã‚¨ãƒ©ãƒ¼ [${job.company_name} - ${job.title}]:`, error)
      errorCount++
    }
  }

  console.log('\n' + '='.repeat(50))
  console.log('ğŸ‰ ç´ä»˜ã‘å®Œäº†')
  console.log('='.repeat(50))
  console.log(`âœ… æˆåŠŸ: ${successCount}ä»¶`)
  console.log(`âš ï¸  PDFæœªç™ºè¦‹: ${notFoundCount}ä»¶`)
  console.log(`âŒ ã‚¨ãƒ©ãƒ¼: ${errorCount}ä»¶`)
  console.log(`ğŸ“Š æˆåŠŸç‡: ${((successCount / jobs.length) * 100).toFixed(1)}%`)
}

linkJobsToPdfs()
